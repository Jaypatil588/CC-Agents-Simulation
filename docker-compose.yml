services:
  frontend:
    build: .
    ports:
      - '5173:5173'
    volumes:
      - .:/usr/src/app
      - /usr/src/app/node_modules
    environment:
      - VITE_CONVEX_URL=http://127.0.0.1:${PORT:-3210}
    networks:
      - ai-town-network
  backend:
    image: ghcr.io/get-convex/convex-backend:latest
    container_name: ai-town-backend-1
    ports:
      - '${PORT:-3210}:3210'
      - '${SITE_PROXY_PORT:-3211}:3211'
    volumes:
      - data:/convex/data
    environment:
      - INSTANCE_NAME=${INSTANCE_NAME:-}
      - INSTANCE_SECRET=${INSTANCE_SECRET:-}
      - CONVEX_RELEASE_VERSION_DEV=${CONVEX_RELEASE_VERSION_DEV:-}
      - ACTIONS_USER_TIMEOUT_SECS=${ACTIONS_USER_TIMEOUT_SECS:-}
      - CONVEX_CLOUD_ORIGIN=${URL_BASE:-http://127.0.0.1}:${PORT:-3210}
      - CONVEX_SITE_ORIGIN=${URL_BASE:-http://127.0.0.1}:${SITE_PROXY_PORT:-3211}
      - DATABASE_URL=${DATABASE_URL:-}
      - OLLAMA_HOST=http://host.docker.internal:11434
    restart: unless-stopped
    # Set memory limit to 6GB to prevent OOM kills during bootstrap
    # Docker Desktop only has 7.65GB total, backend was using 5.6GB+ and getting killed
    deploy:
      resources:
        limits:
          memory: 6G
        reservations:
          memory: 4G
    networks:
      - ai-town-network

  dashboard:
    image: ghcr.io/get-convex/convex-dashboard:latest
    ports:
      - '${DASHBOARD_PORT:-6791}:6791'
    environment:
      - NEXT_PUBLIC_DEPLOYMENT_URL=http://127.0.0.1:${PORT:-3210}
    depends_on:
      backend:
        condition: service_started

volumes:
  data:

networks:
  ai-town-network:
    driver: bridge
